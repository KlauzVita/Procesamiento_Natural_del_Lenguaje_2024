{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Actividad 6: Predicción de Países\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En esta actividad se abordará la exploración de vectores de palabras para la predicción de países.\n",
    "\n",
    "En el procesamiento del lenguaje natural, representamos cada palabra como un vector que consta de números.\n",
    "El vector codifica el significado de la palabra. Estos números (o pesos) para cada palabra se aprenden usando modelos de aprendizaje automático. En lugar de hacerte codificar el modelo de aprendizaje automático utilizaremos algunos vectores de palabras entrenados. En esta actividad se realizará lo siguiente:\n",
    "\n",
    "- Predecir analogías entre palabras\n",
    "- Usar el algoritmo de PCA que reduce la dimensionalidad de los wordembeddings para plotearlos en 2 dimensiones.\n",
    "- Comparar los wordembeddings usando la métrica de la similitud por coseno.\n",
    "\n",
    "\n",
    "\n",
    "###  Importando los datos\n",
    "\n",
    "Como de costumbre, comienza importando algunas bibliotecas Python esenciales y luego carga el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/capitals.txt', delimiter=' ')\n",
    "data.columns=['city1', 'country1', 'city2', 'country2']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Tenga en cuenta que debido a que el conjunto de datos de de vectores palabras de Google News original es de aproximadamente 3,64 gigabytes, en este notebook no podríamos manejar el conjunto de archivos completo. Así que vamos a analizar un sample de wordembeddings qué está guardado en en un archivo pickle llamado `word_embeddings_capitals.p`\n",
    "\n",
    "Si deseas descargar el conjunto de datos completo:\n",
    "\n",
    "- Descargue el conjunto de datos de esta [página](https://code.google.com/archive/p/word2vec/).\n",
    "- Busque en la página 'GoogleNews-vectors-negative300.bin.gz' y haga clic en el enlace para descargar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos los wordembeddings como un [diccionario de Python](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) hay que cargarlo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada una de los wordembedings es un vector de 300 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir relaciones entre palabras\n",
    "\n",
    "\n",
    "Ahora escribirá una función que utilizará los wordembeddings para predecir relaciones entre palabras.\n",
    "* La función tomará como entrada tres palabras.\n",
    "* Los dos primeros están relacionados entre sí.\n",
    "* Predecirá una cuarta palabra que está relacionada con la tercera palabra de manera similar a como las dos primeras palabras están relacionadas entre sí.\n",
    "* Como ejemplo, \"Atenas es para Grecia como Bangkok es para ______\"?\n",
    "* Escribirás un programa que sea capaz de encontrar la cuarta palabra.\n",
    "\n",
    "\n",
    "Una analogía similar sería la siguiente:\n",
    "\n",
    "<img src = './Figures/vectors.jpg' width=\"width\" height=\"height\" style=\"width:467px;height:200px;\"/>\n",
    "\n",
    "Implementarás una función que te puede indicar la capital de un país.\n",
    "Debe utilizar la misma metodología que se muestra en la figura anterior. Para hacer esto,\n",
    "calcular primero calculará la métrica de similitud del coseno o la distancia euclidiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similitud por Coseno\n",
    "\n",
    "La función de similitud del coseno es:\n",
    "\n",
    "$$\\cos (\\theta)=\\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\|\\|\\mathbf{B}\\|}=\\frac{\\sum_{i=1}^{n} A_{i} B_{i}}{\\sqrt{\\sum_{i=1}^{n} A_{i}^{2}} \\sqrt{\\sum_{i=1}^{n} B_{i}^{2}}}\\tag{1}$$\n",
    "\n",
    "$ A $ y $ B $ representan los vectores de palabras y $ A_i $ o $ B_i $ representan el índice i de ese vector.\n",
    "& Tenga en cuenta que si A y B son idénticos, obtendrá $ cos (\\theta) = 1 $.\n",
    "\n",
    "* De lo contrario, si son totalmente opuestos, es decir, $ A = -B $, obtendría $ cos (\\theta) = -1 $.\n",
    "* Si obtiene $ cos (\\ theta) = 0 $, eso significa que son ortogonales (o perpendiculares).\n",
    "* Los números entre 0 y 1 indican una puntuación de similitud.\n",
    "* Los números entre -1-0 indican una puntuación de disimilitud.\n",
    "\n",
    "**Instrucciones**: Implemente una función que tome dos vectores de palabras y calcule la distancia del coseno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distancia Euclideana\n",
    "\n",
    "Ahora implementará una función que calcula la similitud entre dos vectores usando la distancia euclidiana.\n",
    "La distancia euclidiana se define como:\n",
    "\n",
    "$$ \\begin{aligned} d(\\mathbf{A}, \\mathbf{B})=d(\\mathbf{B}, \\mathbf{A}) &=\\sqrt{\\left(A_{1}-B_{1}\\right)^{2}+\\left(A_{2}-B_{2}\\right)^{2}+\\cdots+\\left(A_{n}-B_{n}\\right)^{2}} \\\\ &=\\sqrt{\\sum_{i=1}^{n}\\left(A_{i}-B_{i}\\right)^{2}} \\end{aligned}$$\n",
    "\n",
    "* $ n $ es el número de elementos del vector\n",
    "* $ A $ y $ B $ son los vectores de palabras correspondientes.\n",
    "* Cuanto más similares sean las palabras, más probable será que la distancia euclidiana se acerque a 0.\n",
    "\n",
    "**Instrucciones**: Escribe una función que calcule la distancia euclidiana entre dos vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean(king,queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Encontrar el país de cada capital\n",
    "\n",
    "Ahora, usará las funciones anteriores para calcular similitudes entre vectores,\n",
    "y utilícelos para encontrar las capitales de los países. Escribirás una función que\n",
    "contiene tres palabras y el diccionario de wordembeddings. Tu tarea es encontrar el país dado las\n",
    "ciudades capitales. Por ejemplo, dadas las siguientes palabras:\n",
    "\n",
    "- 1: Athens 2: Greece 3: Baghdad,\n",
    "\n",
    "su tarea es predecir el país 4: Irak.\n",
    "\n",
    "**Instrucciones**: \n",
    "\n",
    "1. Para predecir la capital, se podría implementar el esquema del ejemplo anterior * Rey - Hombre + Mujer = Reina * en una función matemática, utilizando los wordembeddings y una función de similitud.\n",
    "\n",
    "2. Iterando en el diccionario de wordembeddings y calculando la similitud de coseno entre los vectores.\n",
    "\n",
    "3. Al finalizar la función devuelve la palabra que tenga el score más alto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_country('Athens','Greece', 'Cairo', word_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count=get_country('Athens', 'Greece', 'Cairo', word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy del Modelo\n",
    "\n",
    "Ahora probará su nueva función en el conjunto de datos y comprobará la precisión del modelo:\n",
    "\n",
    "$$\\text{Accuracy}=\\frac{\\text{Correct # of predictions}}{\\text{Total # of predictions}}$$\n",
    "\n",
    "**Instrucciones**: Escriba un programa que pueda calcular la precisión del conjunto de datos que se le proporcionó. Tienes que iterar sobre cada fila para obtener las palabras correspondientes e introducirlas en la función `get_country` anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotear los vectores usando PCA\n",
    "\n",
    "Ahora utilizaremos la técnica conocida como [*principal component analysis* (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) para reducir la dimensionalidad de nuestros vectores palabras.\n",
    "Como vimos, estamos trabajando en un espacio de 300 dimensiones en este caso.\n",
    "Aunque desde una perspectiva computacional pudimos realizar un buen trabajo,\n",
    "es imposible visualizar resultados en espacios de dimensiones tan altos.\n",
    "\n",
    "Podemos pensar en el algoritmo de PCA como un método que proyecta nuestros vectores en un espacio de dimensión menor, manteniendo la máxima información sobre los vectores originales.\n",
    "\n",
    "Verá que cuando se mapeen las palabras, las palabras similares se agruparán\n",
    "uno al lado del otro. Por ejemplo, las palabras 'triste', 'feliz', 'alegre' describen\n",
    "emoción y se supone que están cerca el uno del otro cuando se ploteen.\n",
    "Las palabras: \"petróleo\", \"gas\" y \"petróleo\" describen los recursos naturales.\n",
    "Palabras como 'ciudad', 'aldea', 'pueblo' pueden verse como sinónimos y describen algo similar.\n",
    "\n",
    "\n",
    "Antes de trazar las palabras, primero debe poder reducir cada vector de palabra\n",
    "con PCA en 2 dimensiones y luego plotearlo. Los pasos para calcular el PCA son los siguientes:\n",
    "\n",
    "1. Normalizar la media de los datos\n",
    "2. Calcule la matriz de covarianza de sus datos ($ \\ Sigma $).\n",
    "3. Calcule los vectores propios y los autovalores de la matriz de covarianza.\n",
    "4. Multiplique los primeros vectores propios K por sus datos normalizados. La transformación debería tener el siguiente aspecto:\n",
    "\n",
    "<img src = './Figures/word_embf.jpg' width=\"width\" height=\"height\" style=\"width:800px;height:200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instrucciones**: \n",
    "\n",
    "Escribirás un programa que tome un conjunto de datos donde cada fila corresponde a un vector de palabra.\n",
    "* Los vectores de palabras son de dimensión 300.\n",
    "* Utilice PCA para cambiar las dimensiones 300 a dimensiones `n_components`.\n",
    "* La nueva matriz debe ser de dimensión `m, n_componentns`.\n",
    "\n",
    "* Primero restamos la media de los datos\n",
    "* Obtenga los valores propios usando `linalg.eigh`. Utilice `eigh` en lugar de` eig`.\n",
    "* Ordene los vectores y valores propios por orden decreciente por valores proipios.\n",
    "* Obtenga un subconjunto de los valores propios (elija cuántos componentes principales desea usar usando `n_components`).\n",
    "* Devuelve la nueva transformación de los datos multiplicando los vectores propios con los datos originales. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora usará su función pca para plotear algunas palabras.\n",
    "Verá que las palabras similares tienden a agruparse unas cerca de otras.\n",
    "A veces, incluso los antónimos tienden a agruparse unos cerca de otros. Antónimos\n",
    "describen lo mismo pero tienden a estar en el otro extremo de la escala\n",
    "Por lo general, se encuentran en la misma ubicación de una oración,\n",
    "tienen las mismas partes del discurso y, por lo tanto, cuando\n",
    "Al aprender las palabras vectores, terminas obteniendo pesos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "coursera": {
   "schema_names": [
    "NLPC1-3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
