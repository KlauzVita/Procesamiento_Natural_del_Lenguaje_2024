{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKHuZic7fkBO"
      },
      "source": [
        "<img style=\"float: left;;\" src='https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/alinco.png?raw=1' /></a>\n",
        "\n",
        "# Modulo I: Stemming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvqWJ0g3fkBQ"
      },
      "source": [
        "A menudo, cuando se busca texto para una determinada palabra clave, es útil que la búsqueda devuelva variaciones de la palabra. Por ejemplo, la búsqueda de \"barco\" también puede devolver \"barcos\" y \"navegación\". Aquí, \"bote\" sería la **raíz** de [bote, navegante, navegación, botes].\n",
        "\n",
        "El Stemming es un método para catalogar palabras relacionadas; esencialmente corta las letras desde el final hasta que se alcanza la raiz. Esto funciona bastante bien en la mayoría de los casos, pero desafortunadamente el inglés tiene muchas excepciones donde se requiere un proceso más sofisticado. De hecho, spaCy no incluye un lematizador, sino que opta por confiar completamente en la lematización. Para aquellos interesados, hay algunos antecedentes sobre esta decisión [aquí] (https://github.com/explosion/spaCy/issues/327).\n",
        "\n",
        "En su lugar, usaremos otra herramienta popular de NLP llamada **nltk**, que significa *Natural Language Toolkit*. https://www.nltk.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AnTYOKefkBR"
      },
      "source": [
        "## Porter Stemmer\n",
        "\n",
        "Una de las herramientas de derivación más comunes y efectivas es el [*Algoritmo de Porter*](https://tartarus.org/martin/PorterStemmer/) desarrollado por Martin Porter en [1980](https://tartarus.org/martin/PorterStemmer/def.txt). El algoritmo emplea cinco fases de reducción de palabras, cada una con su propio conjunto de reglas de mapeo. En la primera fase, se definen reglas de mapeo de sufijos simples, tales como:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DILSFMUlfkBR"
      },
      "source": [
        "![stemming1.png](https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/stemming1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umjuRveKfkBR"
      },
      "source": [
        "De un conjunto dado de reglas derivadas, solo se aplica una regla, basada en el sufijo más largo S1. Entonces, `caresses` se reduce a `caress` pero no a `cares`.\n",
        "\n",
        "Las fases más sofisticadas consideran la longitud / complejidad de la palabra antes de aplicar una regla. Por ejemplo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkFuMC3sfkBR"
      },
      "source": [
        "![stemming1.png](https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/stemming2.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHQtmYCkfkBR"
      },
      "source": [
        "Aquí `m> 0` describe la\" medida \"de la raíz, de modo que la regla se aplica a todas las raíces menos a las más básicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Vey4ql0fkBS"
      },
      "outputs": [],
      "source": [
        "# importar nltk\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4rc0XU8fkBS"
      },
      "outputs": [],
      "source": [
        "p_stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']"
      ],
      "metadata": {
        "id": "0QqDkDNpgYO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word + \"---> \" + p_stemmer.stem(word))"
      ],
      "metadata": {
        "id": "ruNdWQe5gYhd",
        "outputId": "734e1da0-302e-4590-de4d-eca2fa3cbb6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run---> run\n",
            "runner---> runner\n",
            "running---> run\n",
            "ran---> ran\n",
            "runs---> run\n",
            "easily---> easili\n",
            "fairly---> fairli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km4CmWNkfkBS"
      },
      "source": [
        "<font color=green>Observe cómo el lematizador reconoce \"runner\" como un sustantivo, no como una forma verbal o un participio. Además, los adverbios \"easily\" y \"fairly\" se derivan de la raíz inusual \"easili\" y \"fairli\".</font>\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4wlFK8cfkBT"
      },
      "source": [
        "## Snowball Stemmer\n",
        "Este es un nombre poco apropiado, ya que Snowball es el nombre de un lenguaje derivado desarrollado por Martin Porter. El algoritmo utilizado aquí se llama más exactamente \"Stemmer inglés\" o \"Stemmer Porter2\". Ofrece una ligera mejora con respecto a al algoritmo original, tanto en lógica como en tiempo de procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNEKT0QpfkBT"
      },
      "outputs": [],
      "source": [
        "#Importar SnowballStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "# Snowball Stemmer requiere que pases como parámetro de entrada el idioma\n",
        "s_stemmer = SnowballStemmer(language='english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gDDsOXWfkBT"
      },
      "outputs": [],
      "source": [
        "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKFtXkETfkBT",
        "outputId": "3f490641-809a-4037-9a22-dbea4c604e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run---->run\n",
            "runner---->runner\n",
            "running---->run\n",
            "ran---->ran\n",
            "runs---->run\n",
            "easily---->easili\n",
            "fairly---->fair\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word + '---->' + s_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Krknm0v4fkBU"
      },
      "source": [
        "<font color=green>En este caso, el stemmer obtuvo casi la misma salida que el algoritmo anterior, con la excepción de que se aplicó \"fairly\" más apropiadamente con \"fair\"</font>\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kry23tTqfkBU"
      },
      "source": [
        "\n",
        "#### probar otras palabras y ver los resultados!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovgz5w0kfkBU"
      },
      "outputs": [],
      "source": [
        "words = ['consolingly']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyzTEEZrfkBV",
        "outputId": "c6df9be0-2026-4989-b0eb-d9391d7a90f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer:\n",
            "consolingly --> consolingli\n"
          ]
        }
      ],
      "source": [
        "print('Porter Stemmer:')\n",
        "for word in words:\n",
        "    print(word+' --> '+p_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5LiGb4fkBV",
        "outputId": "a2d91f7e-0b81-4a01-ce58-06a7d3fa9039",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter2 Stemmer:\n",
            "consolingly --> consol\n"
          ]
        }
      ],
      "source": [
        "print('Porter2 Stemmer:')\n",
        "for word in words:\n",
        "    print(word+' --> '+s_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdsF8FArfkBV"
      },
      "source": [
        "___\n",
        "El Stemming tiene sus inconvenientes. Si se le da el token \"saw\", la derivación siempre podría devolver `saw`, mientras que la lematización probablemente devolvería `see` o `saw` dependiendo de si el uso del token fue como un verbo o como un sustantivo. Como ejemplo, considere lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gWk8_HhfkBV",
        "outputId": "93233ccc-48e6-4344-aef3-258d1b17c72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I --> i\n",
            "am --> am\n",
            "meeting --> meet\n",
            "him --> him\n",
            "tomorrow --> tomorrow\n",
            "at --> at\n",
            "the --> the\n",
            "meeting --> meet\n"
          ]
        }
      ],
      "source": [
        "phrase = 'I am meeting him tomorrow at the meeting'\n",
        "for word in phrase.split():\n",
        "    print(word+' --> '+p_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m2QTWdffkBV"
      },
      "source": [
        "Aquí, la palabra \"meeting\" aparece dos veces: una vez como verbo y otra como sustantivo, y sin embargo, el lematizador trata a ambos por igual.."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}