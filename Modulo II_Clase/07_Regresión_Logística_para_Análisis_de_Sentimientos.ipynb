{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwY1E6Ac5uew"
      },
      "source": [
        "<img style=\"float: left;;\" src='https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/alinco.png?raw=1' /></a>\n",
        "\n",
        "# Modulo I: Regresión Logística para Análisis de Sentimientos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Aq4ke75ue0"
      },
      "source": [
        "## Importar librerías y funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXh93k_U5ue1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "kTcaMZvj5ue1"
      },
      "outputs": [],
      "source": [
        "# agregue la carpeta, tmp2, desde nuestro espacio de trabajo local que contiene archivos de corpus descargados previamente a la ruta de datos de nltk\n",
        "# esto permite importar estos archivos sin descargarlos nuevamente cuando actualizamos nuestro espacio de trabajo\n",
        "filePath = f\"{getcwd()}/../tmp2\"\n",
        "nltk.data.path.append(filePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rhXg3NiD5ue2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "from utils import process_tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXHe8aoA5ue2"
      },
      "source": [
        "### Prepara los datos\n",
        "* `twitter_samples` contiene subconjuntos de 5,000 tweets positivos, 5,000 tweets negativos y el conjunto completo de 10,000 tweets.\n",
        "     * Si utiliza los tres conjuntos de datos, introduciríamos duplicados de los tweets positivos y negativos.\n",
        "     * Seleccionará solo los cinco mil tweets positivos y los cinco mil tweets negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "n2j6L1cB5ue3"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(%colors)"
      ],
      "metadata": {
        "id": "-4gXg0UiCDVS",
        "outputId": "5e4f6168-6a17-4184-bed0-d00ee096c69a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qCl8pQW5ue3"
      },
      "source": [
        "* Train test split: 20% para test, y 80% para train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "B_gjUrDV5ue3"
      },
      "outputs": [],
      "source": [
        "# split the data into two pieces, one for training and one for testing (validation set)\n",
        "\n",
        "#Test y train para tweets positivos\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "#Test y train para tweets negativos\n",
        "\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "# Datos de entrenamiento\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_GNrrBM5ue4"
      },
      "source": [
        "* Creear una matriz de etiquetas positivas y negativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "tvLLN9525ue4"
      },
      "outputs": [],
      "source": [
        "# combinar tweets positivos y negativos\n",
        "train_y = np.append(np.ones((len(train_pos),1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos),1)), np.zeros((len(test_neg),1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DGElzEbJ5ue4",
        "outputId": "21276e9a-1a62-463d-ef30-e3011f30f6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 8000)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# imprimir test y train\n",
        "len(test_y), len(train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "iDawaxjK5ue4",
        "outputId": "6f235c2a-1985-4976-e54d-8c1c603a2600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the Utilities Constructor\n"
          ]
        }
      ],
      "source": [
        "# crear el diccionario de frecuencias\n",
        "from utilss import Utilities as prep\n",
        "a = prep()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "w_uOfs5EEDUt",
        "outputId": "3a6d39fe-8ae3-4bb1-b014-9bf732c53b6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = a.build_freqs(train_x, train_y)"
      ],
      "metadata": {
        "id": "ZvBPNd57D7xU"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs"
      ],
      "metadata": {
        "id": "sSl5QNG3EJbe",
        "outputId": "aae3ab3f-6d19-4cf4-a78d-36760521da2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('followfriday', 1.0): 23,\n",
              " ('top', 1.0): 30,\n",
              " ('engag', 1.0): 7,\n",
              " ('member', 1.0): 14,\n",
              " ('commun', 1.0): 27,\n",
              " ('week', 1.0): 72,\n",
              " (':)', 1.0): 2847,\n",
              " ('hey', 1.0): 60,\n",
              " ('jame', 1.0): 7,\n",
              " ('odd', 1.0): 2,\n",
              " (':/', 1.0): 5,\n",
              " ('pleas', 1.0): 80,\n",
              " ('call', 1.0): 27,\n",
              " ('contact', 1.0): 4,\n",
              " ('centr', 1.0): 1,\n",
              " ('02392441234', 1.0): 1,\n",
              " ('abl', 1.0): 6,\n",
              " ('assist', 1.0): 1,\n",
              " ('mani', 1.0): 28,\n",
              " ('thank', 1.0): 504,\n",
              " ('listen', 1.0): 14,\n",
              " ('last', 1.0): 39,\n",
              " ('night', 1.0): 55,\n",
              " ('bleed', 1.0): 2,\n",
              " ('amaz', 1.0): 41,\n",
              " ('track', 1.0): 5,\n",
              " ('scotland', 1.0): 2,\n",
              " ('congrat', 1.0): 15,\n",
              " ('yeaaah', 1.0): 1,\n",
              " ('yipppi', 1.0): 1,\n",
              " ('accnt', 1.0): 2,\n",
              " ('verifi', 1.0): 2,\n",
              " ('rqst', 1.0): 1,\n",
              " ('succeed', 1.0): 1,\n",
              " ('got', 1.0): 57,\n",
              " ('blue', 1.0): 8,\n",
              " ('tick', 1.0): 1,\n",
              " ('mark', 1.0): 1,\n",
              " ('fb', 1.0): 4,\n",
              " ('profil', 1.0): 2,\n",
              " ('15', 1.0): 4,\n",
              " ('day', 1.0): 187,\n",
              " ('one', 1.0): 90,\n",
              " ('irresist', 1.0): 2,\n",
              " ('flipkartfashionfriday', 1.0): 16,\n",
              " ('like', 1.0): 187,\n",
              " ('keep', 1.0): 55,\n",
              " ('love', 1.0): 336,\n",
              " ('custom', 1.0): 4,\n",
              " ('wait', 1.0): 55,\n",
              " ('long', 1.0): 27,\n",
              " ('hope', 1.0): 113,\n",
              " ('enjoy', 1.0): 57,\n",
              " ('happi', 1.0): 161,\n",
              " ('friday', 1.0): 91,\n",
              " ('lwwf', 1.0): 1,\n",
              " ('second', 1.0): 8,\n",
              " ('thought', 1.0): 21,\n",
              " ('’', 1.0): 17,\n",
              " ('enough', 1.0): 16,\n",
              " ('time', 1.0): 100,\n",
              " ('dd', 1.0): 1,\n",
              " ('new', 1.0): 111,\n",
              " ('short', 1.0): 6,\n",
              " ('enter', 1.0): 9,\n",
              " ('system', 1.0): 2,\n",
              " ('sheep', 1.0): 1,\n",
              " ('must', 1.0): 14,\n",
              " ('buy', 1.0): 9,\n",
              " ('jgh', 1.0): 4,\n",
              " ('go', 1.0): 120,\n",
              " ('bayan', 1.0): 1,\n",
              " (':d', 1.0): 498,\n",
              " ('bye', 1.0): 5,\n",
              " ('act', 1.0): 6,\n",
              " ('mischiev', 1.0): 1,\n",
              " ('etl', 1.0): 1,\n",
              " ('layer', 1.0): 1,\n",
              " ('in-hous', 1.0): 1,\n",
              " ('wareh', 1.0): 1,\n",
              " ('app', 1.0): 12,\n",
              " ('katamari', 1.0): 1,\n",
              " ('well', 1.0): 66,\n",
              " ('…', 1.0): 31,\n",
              " ('name', 1.0): 12,\n",
              " ('impli', 1.0): 1,\n",
              " (':p', 1.0): 104,\n",
              " ('influenc', 1.0): 16,\n",
              " ('big', 1.0): 27,\n",
              " ('...', 1.0): 227,\n",
              " ('juici', 1.0): 3,\n",
              " ('selfi', 1.0): 11,\n",
              " ('follow', 1.0): 319,\n",
              " ('perfect', 1.0): 17,\n",
              " ('alreadi', 1.0): 19,\n",
              " ('know', 1.0): 120,\n",
              " (\"what'\", 1.0): 14,\n",
              " ('great', 1.0): 134,\n",
              " ('opportun', 1.0): 17,\n",
              " ('junior', 1.0): 2,\n",
              " ('triathlet', 1.0): 1,\n",
              " ('age', 1.0): 2,\n",
              " ('12', 1.0): 5,\n",
              " ('13', 1.0): 5,\n",
              " ('gatorad', 1.0): 1,\n",
              " ('seri', 1.0): 4,\n",
              " ('get', 1.0): 164,\n",
              " ('entri', 1.0): 3,\n",
              " ('lay', 1.0): 3,\n",
              " ('greet', 1.0): 4,\n",
              " ('card', 1.0): 6,\n",
              " ('rang', 1.0): 2,\n",
              " ('print', 1.0): 3,\n",
              " ('today', 1.0): 86,\n",
              " ('job', 1.0): 34,\n",
              " (':-)', 1.0): 543,\n",
              " (\"friend'\", 1.0): 3,\n",
              " ('lunch', 1.0): 3,\n",
              " ('yummm', 1.0): 1,\n",
              " ('nostalgia', 1.0): 1,\n",
              " ('tb', 1.0): 1,\n",
              " ('ku', 1.0): 1,\n",
              " ('id', 1.0): 8,\n",
              " ('conflict', 1.0): 1,\n",
              " ('help', 1.0): 37,\n",
              " (\"here'\", 1.0): 20,\n",
              " ('screenshot', 1.0): 2,\n",
              " ('work', 1.0): 88,\n",
              " ('hi', 1.0): 154,\n",
              " ('liv', 1.0): 2,\n",
              " ('hello', 1.0): 49,\n",
              " ('need', 1.0): 62,\n",
              " ('someth', 1.0): 25,\n",
              " ('u', 1.0): 136,\n",
              " ('fm', 1.0): 2,\n",
              " ('twitter', 1.0): 25,\n",
              " ('—', 1.0): 22,\n",
              " ('sure', 1.0): 37,\n",
              " ('thing', 1.0): 48,\n",
              " ('dm', 1.0): 34,\n",
              " ('x', 1.0): 50,\n",
              " (\"i'v\", 1.0): 25,\n",
              " ('heard', 1.0): 9,\n",
              " ('four', 1.0): 5,\n",
              " ('season', 1.0): 5,\n",
              " ('pretti', 1.0): 17,\n",
              " ('dope', 1.0): 2,\n",
              " ('penthous', 1.0): 1,\n",
              " ('obv', 1.0): 1,\n",
              " ('gobigorgohom', 1.0): 1,\n",
              " ('fun', 1.0): 45,\n",
              " (\"y'all\", 1.0): 3,\n",
              " ('yeah', 1.0): 30,\n",
              " ('suppos', 1.0): 6,\n",
              " ('lol', 1.0): 48,\n",
              " ('chat', 1.0): 9,\n",
              " ('bit', 1.0): 16,\n",
              " ('youth', 1.0): 14,\n",
              " ('💅🏽', 1.0): 1,\n",
              " ('💋', 1.0): 2,\n",
              " ('seen', 1.0): 6,\n",
              " ('year', 1.0): 33,\n",
              " ('rest', 1.0): 9,\n",
              " ('goe', 1.0): 4,\n",
              " ('quickli', 1.0): 3,\n",
              " ('bed', 1.0): 8,\n",
              " ('music', 1.0): 15,\n",
              " ('fix', 1.0): 6,\n",
              " ('dream', 1.0): 17,\n",
              " ('spiritu', 1.0): 1,\n",
              " ('ritual', 1.0): 1,\n",
              " ('festiv', 1.0): 7,\n",
              " ('népal', 1.0): 1,\n",
              " ('begin', 1.0): 4,\n",
              " ('line-up', 1.0): 4,\n",
              " ('left', 1.0): 10,\n",
              " ('see', 1.0): 156,\n",
              " ('sarah', 1.0): 4,\n",
              " ('send', 1.0): 17,\n",
              " ('us', 1.0): 91,\n",
              " ('email', 1.0): 22,\n",
              " ('bitsy@bitdefender.com', 1.0): 1,\n",
              " (\"we'll\", 1.0): 12,\n",
              " ('asap', 1.0): 5,\n",
              " ('kik', 1.0): 16,\n",
              " ('hatessuc', 1.0): 1,\n",
              " ('32429', 1.0): 1,\n",
              " ('kikm', 1.0): 1,\n",
              " ('lgbt', 1.0): 2,\n",
              " ('tinder', 1.0): 1,\n",
              " ('nsfw', 1.0): 1,\n",
              " ('akua', 1.0): 1,\n",
              " ('cumshot', 1.0): 1,\n",
              " ('come', 1.0): 63,\n",
              " ('hous', 1.0): 5,\n",
              " ('nsn_supplement', 1.0): 1,\n",
              " ('effect', 1.0): 2,\n",
              " ('press', 1.0): 1,\n",
              " ('releas', 1.0): 11,\n",
              " ('distribut', 1.0): 1,\n",
              " ('result', 1.0): 2,\n",
              " ('link', 1.0): 13,\n",
              " ('remov', 1.0): 3,\n",
              " ('pressreleas', 1.0): 1,\n",
              " ('newsdistribut', 1.0): 1,\n",
              " ('bam', 1.0): 44,\n",
              " ('bestfriend', 1.0): 50,\n",
              " ('lot', 1.0): 80,\n",
              " ('warsaw', 1.0): 44,\n",
              " ('<3', 1.0): 118,\n",
              " ('x46', 1.0): 1,\n",
              " ('everyon', 1.0): 45,\n",
              " ('watch', 1.0): 32,\n",
              " ('documentari', 1.0): 1,\n",
              " ('earthl', 1.0): 1,\n",
              " ('youtub', 1.0): 8,\n",
              " ('support', 1.0): 25,\n",
              " ('buuut', 1.0): 1,\n",
              " ('oh', 1.0): 44,\n",
              " ('look', 1.0): 109,\n",
              " ('forward', 1.0): 20,\n",
              " ('visit', 1.0): 25,\n",
              " ('next', 1.0): 37,\n",
              " ('letsgetmessi', 1.0): 1,\n",
              " ('jo', 1.0): 1,\n",
              " ('make', 1.0): 69,\n",
              " ('feel', 1.0): 33,\n",
              " ('better', 1.0): 40,\n",
              " ('never', 1.0): 31,\n",
              " ('anyon', 1.0): 7,\n",
              " ('kpop', 1.0): 1,\n",
              " ('flesh', 1.0): 1,\n",
              " ('good', 1.0): 191,\n",
              " ('girl', 1.0): 34,\n",
              " ('best', 1.0): 49,\n",
              " ('wish', 1.0): 29,\n",
              " ('reason', 1.0): 10,\n",
              " ('epic', 1.0): 1,\n",
              " ('soundtrack', 1.0): 1,\n",
              " ('shout', 1.0): 11,\n",
              " ('ad', 1.0): 10,\n",
              " ('video', 1.0): 29,\n",
              " ('playlist', 1.0): 5,\n",
              " ('would', 1.0): 70,\n",
              " ('dear', 1.0): 15,\n",
              " ('jordan', 1.0): 1,\n",
              " ('okay', 1.0): 31,\n",
              " ('fake', 1.0): 1,\n",
              " ('gameplay', 1.0): 1,\n",
              " (';)', 1.0): 22,\n",
              " ('haha', 1.0): 44,\n",
              " ('im', 1.0): 38,\n",
              " ('kid', 1.0): 13,\n",
              " ('stuff', 1.0): 11,\n",
              " ('exactli', 1.0): 5,\n",
              " ('product', 1.0): 11,\n",
              " ('line', 1.0): 6,\n",
              " ('etsi', 1.0): 1,\n",
              " ('shop', 1.0): 12,\n",
              " ('check', 1.0): 38,\n",
              " ('vacat', 1.0): 5,\n",
              " ('recharg', 1.0): 1,\n",
              " ('normal', 1.0): 5,\n",
              " ('charger', 1.0): 2,\n",
              " ('asleep', 1.0): 7,\n",
              " ('talk', 1.0): 37,\n",
              " ('sooo', 1.0): 6,\n",
              " ('someon', 1.0): 29,\n",
              " ('text', 1.0): 12,\n",
              " ('ye', 1.0): 60,\n",
              " ('bet', 1.0): 6,\n",
              " (\"he'll\", 1.0): 2,\n",
              " ('fit', 1.0): 2,\n",
              " ('hear', 1.0): 24,\n",
              " ('speech', 1.0): 1,\n",
              " ('piti', 1.0): 2,\n",
              " ('green', 1.0): 2,\n",
              " ('garden', 1.0): 5,\n",
              " ('midnight', 1.0): 1,\n",
              " ('sun', 1.0): 6,\n",
              " ('beauti', 1.0): 45,\n",
              " ('canal', 1.0): 1,\n",
              " ('dasvidaniya', 1.0): 1,\n",
              " ('till', 1.0): 16,\n",
              " ('scout', 1.0): 1,\n",
              " ('sg', 1.0): 1,\n",
              " ('futur', 1.0): 9,\n",
              " ('wlan', 1.0): 1,\n",
              " ('pro', 1.0): 4,\n",
              " ('confer', 1.0): 1,\n",
              " ('asia', 1.0): 1,\n",
              " ('chang', 1.0): 20,\n",
              " ('lollipop', 1.0): 1,\n",
              " ('🍭', 1.0): 1,\n",
              " ('nez', 1.0): 1,\n",
              " ('agnezmo', 1.0): 1,\n",
              " ('oley', 1.0): 1,\n",
              " ('mama', 1.0): 1,\n",
              " ('stand', 1.0): 6,\n",
              " ('stronger', 1.0): 1,\n",
              " ('god', 1.0): 14,\n",
              " ('misti', 1.0): 1,\n",
              " ('babi', 1.0): 17,\n",
              " ('cute', 1.0): 21,\n",
              " ('woohoo', 1.0): 3,\n",
              " (\"can't\", 1.0): 31,\n",
              " ('sign', 1.0): 9,\n",
              " ('yet', 1.0): 12,\n",
              " ('still', 1.0): 37,\n",
              " ('think', 1.0): 48,\n",
              " ('mka', 1.0): 5,\n",
              " ('liam', 1.0): 5,\n",
              " ('access', 1.0): 3,\n",
              " ('welcom', 1.0): 54,\n",
              " ('stat', 1.0): 51,\n",
              " ('arriv', 1.0): 57,\n",
              " ('1', 1.0): 60,\n",
              " ('unfollow', 1.0): 53,\n",
              " ('via', 1.0): 60,\n",
              " ('surpris', 1.0): 10,\n",
              " ('figur', 1.0): 5,\n",
              " ('happybirthdayemilybett', 1.0): 1,\n",
              " ('sweet', 1.0): 16,\n",
              " ('talent', 1.0): 4,\n",
              " ('2', 1.0): 41,\n",
              " ('plan', 1.0): 21,\n",
              " ('drain', 1.0): 1,\n",
              " ('gotta', 1.0): 4,\n",
              " ('timezon', 1.0): 1,\n",
              " ('parent', 1.0): 4,\n",
              " ('proud', 1.0): 11,\n",
              " ('least', 1.0): 14,\n",
              " ('mayb', 1.0): 17,\n",
              " ('sometim', 1.0): 11,\n",
              " ('grade', 1.0): 4,\n",
              " ('al', 1.0): 3,\n",
              " ('grand', 1.0): 4,\n",
              " ('manila_bro', 1.0): 1,\n",
              " ('chosen', 1.0): 1,\n",
              " ('let', 1.0): 57,\n",
              " ('around', 1.0): 14,\n",
              " ('..', 1.0): 100,\n",
              " ('side', 1.0): 13,\n",
              " ('world', 1.0): 23,\n",
              " ('eh', 1.0): 2,\n",
              " ('take', 1.0): 30,\n",
              " ('care', 1.0): 12,\n",
              " ('final', 1.0): 24,\n",
              " ('fuck', 1.0): 20,\n",
              " ('weekend', 1.0): 61,\n",
              " ('real', 1.0): 18,\n",
              " ('x45', 1.0): 1,\n",
              " ('join', 1.0): 21,\n",
              " ('hushedcallwithfraydo', 1.0): 1,\n",
              " ('gift', 1.0): 7,\n",
              " ('yeahhh', 1.0): 1,\n",
              " ('hushedpinwithsammi', 1.0): 2,\n",
              " ('event', 1.0): 7,\n",
              " ('might', 1.0): 21,\n",
              " ('luv', 1.0): 4,\n",
              " ('realli', 1.0): 66,\n",
              " ('appreci', 1.0): 28,\n",
              " ('share', 1.0): 41,\n",
              " ('wow', 1.0): 14,\n",
              " ('tom', 1.0): 5,\n",
              " ('gym', 1.0): 3,\n",
              " ('monday', 1.0): 7,\n",
              " ('invit', 1.0): 15,\n",
              " ('scope', 1.0): 5,\n",
              " ('friend', 1.0): 40,\n",
              " ('nude', 1.0): 1,\n",
              " ('sleep', 1.0): 35,\n",
              " ('birthday', 1.0): 53,\n",
              " ('want', 1.0): 69,\n",
              " ('t-shirt', 1.0): 2,\n",
              " ('cool', 1.0): 29,\n",
              " ('haw', 1.0): 1,\n",
              " ('phela', 1.0): 1,\n",
              " ('mom', 1.0): 7,\n",
              " ('obvious', 1.0): 1,\n",
              " ('princ', 1.0): 1,\n",
              " ('charm', 1.0): 1,\n",
              " ('stage', 1.0): 2,\n",
              " ('luck', 1.0): 26,\n",
              " ('tyler', 1.0): 1,\n",
              " ('hipster', 1.0): 1,\n",
              " ('glass', 1.0): 3,\n",
              " ('marti', 1.0): 2,\n",
              " ('glad', 1.0): 41,\n",
              " ('done', 1.0): 40,\n",
              " ('afternoon', 1.0): 7,\n",
              " ('read', 1.0): 27,\n",
              " ('kahfi', 1.0): 1,\n",
              " ('finish', 1.0): 15,\n",
              " ('ohmyg', 1.0): 1,\n",
              " ('yaya', 1.0): 3,\n",
              " ('dub', 1.0): 1,\n",
              " ('stalk', 1.0): 2,\n",
              " ('ig', 1.0): 3,\n",
              " ('gondooo', 1.0): 1,\n",
              " ('moo', 1.0): 2,\n",
              " ('tologooo', 1.0): 1,\n",
              " ('becom', 1.0): 8,\n",
              " ('detail', 1.0): 8,\n",
              " ('zzz', 1.0): 1,\n",
              " ('xx', 1.0): 33,\n",
              " ('physiotherapi', 1.0): 1,\n",
              " ('hashtag', 1.0): 3,\n",
              " ('💪', 1.0): 1,\n",
              " ('monica', 1.0): 1,\n",
              " ('miss', 1.0): 17,\n",
              " ('sound', 1.0): 20,\n",
              " ('morn', 1.0): 68,\n",
              " (\"that'\", 1.0): 49,\n",
              " ('x43', 1.0): 1,\n",
              " ('definit', 1.0): 20,\n",
              " ('tri', 1.0): 34,\n",
              " ('tonight', 1.0): 15,\n",
              " ('took', 1.0): 7,\n",
              " ('advic', 1.0): 6,\n",
              " ('treviso', 1.0): 1,\n",
              " ('concert', 1.0): 23,\n",
              " ('citi', 1.0): 26,\n",
              " ('countri', 1.0): 22,\n",
              " (\"i'll\", 1.0): 73,\n",
              " ('start', 1.0): 56,\n",
              " ('fine', 1.0): 7,\n",
              " ('gorgeou', 1.0): 9,\n",
              " ('xo', 1.0): 2,\n",
              " ('oven', 1.0): 2,\n",
              " ('roast', 1.0): 1,\n",
              " ('garlic', 1.0): 1,\n",
              " ('oliv', 1.0): 1,\n",
              " ('oil', 1.0): 4,\n",
              " ('dri', 1.0): 4,\n",
              " ('tomato', 1.0): 1,\n",
              " ('basil', 1.0): 1,\n",
              " ('centuri', 1.0): 1,\n",
              " ('tuna', 1.0): 1,\n",
              " ('right', 1.0): 38,\n",
              " ('back', 1.0): 74,\n",
              " ('atchya', 1.0): 1,\n",
              " ('even', 1.0): 26,\n",
              " ('almost', 1.0): 8,\n",
              " ('chanc', 1.0): 3,\n",
              " ('cheer', 1.0): 17,\n",
              " ('po', 1.0): 3,\n",
              " ('ice', 1.0): 6,\n",
              " ('cream', 1.0): 6,\n",
              " ('agre', 1.0): 13,\n",
              " ('100', 1.0): 6,\n",
              " ('heheheh', 1.0): 2,\n",
              " ('that', 1.0): 10,\n",
              " ('point', 1.0): 11,\n",
              " ('stay', 1.0): 20,\n",
              " ('home', 1.0): 20,\n",
              " ('soon', 1.0): 38,\n",
              " ('promis', 1.0): 4,\n",
              " ('web', 1.0): 4,\n",
              " ('whatsapp', 1.0): 3,\n",
              " ('volta', 1.0): 1,\n",
              " ('funcionar', 1.0): 1,\n",
              " ('com', 1.0): 2,\n",
              " ('iphon', 1.0): 7,\n",
              " ('jailbroken', 1.0): 1,\n",
              " ('later', 1.0): 11,\n",
              " ('34', 1.0): 3,\n",
              " ('min', 1.0): 7,\n",
              " ('leia', 1.0): 1,\n",
              " ('appear', 1.0): 3,\n",
              " ('hologram', 1.0): 1,\n",
              " ('r2d2', 1.0): 1,\n",
              " ('w', 1.0): 16,\n",
              " ('messag', 1.0): 9,\n",
              " ('obi', 1.0): 1,\n",
              " ('wan', 1.0): 1,\n",
              " ('sit', 1.0): 7,\n",
              " ('luke', 1.0): 4,\n",
              " ('inter', 1.0): 1,\n",
              " ('3', 1.0): 25,\n",
              " ('ucl', 1.0): 1,\n",
              " ('arsen', 1.0): 2,\n",
              " ('small', 1.0): 1,\n",
              " ('team', 1.0): 24,\n",
              " ('pass', 1.0): 10,\n",
              " ('🚂', 1.0): 1,\n",
              " ('dewsburi', 1.0): 2,\n",
              " ('railway', 1.0): 1,\n",
              " ('station', 1.0): 4,\n",
              " ('dew', 1.0): 1,\n",
              " ('west', 1.0): 1,\n",
              " ('yorkshir', 1.0): 2,\n",
              " ('430', 1.0): 1,\n",
              " ('smh', 1.0): 2,\n",
              " ('9:25', 1.0): 1,\n",
              " ('live', 1.0): 21,\n",
              " ('strang', 1.0): 4,\n",
              " ('imagin', 1.0): 5,\n",
              " ('megan', 1.0): 1,\n",
              " ('masaantoday', 1.0): 4,\n",
              " ('a4', 1.0): 3,\n",
              " ('shweta', 1.0): 1,\n",
              " ('tripathi', 1.0): 1,\n",
              " ('5', 1.0): 15,\n",
              " ('20', 1.0): 5,\n",
              " ('kurta', 1.0): 3,\n",
              " ('half', 1.0): 6,\n",
              " ('number', 1.0): 11,\n",
              " ('wsalelov', 1.0): 14,\n",
              " ('ah', 1.0): 12,\n",
              " ('larri', 1.0): 3,\n",
              " ('anyway', 1.0): 14,\n",
              " ('kinda', 1.0): 12,\n",
              " ('goood', 1.0): 1,\n",
              " ('life', 1.0): 36,\n",
              " ('enn', 1.0): 1,\n",
              " ('could', 1.0): 25,\n",
              " ('warmup', 1.0): 1,\n",
              " ('15th', 1.0): 2,\n",
              " ('bath', 1.0): 6,\n",
              " ('dum', 1.0): 2,\n",
              " ('andar', 1.0): 1,\n",
              " ('ram', 1.0): 1,\n",
              " ('sampath', 1.0): 1,\n",
              " ('sona', 1.0): 1,\n",
              " ('mohapatra', 1.0): 1,\n",
              " ('samantha', 1.0): 1,\n",
              " ('edward', 1.0): 1,\n",
              " ('mein', 1.0): 1,\n",
              " ('tulan', 1.0): 1,\n",
              " ('razi', 1.0): 2,\n",
              " ('wah', 1.0): 2,\n",
              " ('josh', 1.0): 1,\n",
              " ('alway', 1.0): 48,\n",
              " ('smile', 1.0): 47,\n",
              " ('pictur', 1.0): 7,\n",
              " ('16.20', 1.0): 1,\n",
              " ('giveitup', 1.0): 1,\n",
              " ('given', 1.0): 3,\n",
              " ('ga', 1.0): 3,\n",
              " ('subsidi', 1.0): 1,\n",
              " ('initi', 1.0): 2,\n",
              " ('propos', 1.0): 3,\n",
              " ('delight', 1.0): 4,\n",
              " ('yesterday', 1.0): 4,\n",
              " ('x42', 1.0): 1,\n",
              " ('lmaoo', 1.0): 2,\n",
              " ('song', 1.0): 16,\n",
              " ('ever', 1.0): 19,\n",
              " ('shall', 1.0): 5,\n",
              " ('littl', 1.0): 29,\n",
              " ('throwback', 1.0): 3,\n",
              " ('outli', 1.0): 1,\n",
              " ('island', 1.0): 2,\n",
              " ('cheung', 1.0): 1,\n",
              " ('chau', 1.0): 1,\n",
              " ('mui', 1.0): 1,\n",
              " ('wo', 1.0): 1,\n",
              " ('total', 1.0): 5,\n",
              " ('differ', 1.0): 10,\n",
              " ('kfckitchentour', 1.0): 2,\n",
              " ('kitchen', 1.0): 3,\n",
              " ('clean', 1.0): 1,\n",
              " (\"i'm\", 1.0): 140,\n",
              " ('cusp', 1.0): 1,\n",
              " ('test', 1.0): 7,\n",
              " ('water', 1.0): 7,\n",
              " ('reward', 1.0): 1,\n",
              " ('arummzz', 1.0): 2,\n",
              " (\"let'\", 1.0): 18,\n",
              " ('drive', 1.0): 9,\n",
              " ('travel', 1.0): 19,\n",
              " ('yogyakarta', 1.0): 3,\n",
              " ('jeep', 1.0): 3,\n",
              " ('indonesia', 1.0): 3,\n",
              " ('instamood', 1.0): 3,\n",
              " ('wanna', 1.0): 23,\n",
              " ('skype', 1.0): 3,\n",
              " ('may', 1.0): 16,\n",
              " ('nice', 1.0): 70,\n",
              " ('friendli', 1.0): 1,\n",
              " ('pretend', 1.0): 2,\n",
              " ('film', 1.0): 8,\n",
              " ('congratul', 1.0): 9,\n",
              " ('winner', 1.0): 3,\n",
              " ('cheesydelight', 1.0): 1,\n",
              " ('contest', 1.0): 5,\n",
              " ('address', 1.0): 8,\n",
              " ('guy', 1.0): 48,\n",
              " ('market', 1.0): 5,\n",
              " ('24/7', 1.0): 1,\n",
              " ('14', 1.0): 1,\n",
              " ('hour', 1.0): 24,\n",
              " ('leav', 1.0): 11,\n",
              " ('without', 1.0): 9,\n",
              " ('delay', 1.0): 1,\n",
              " ('actual', 1.0): 13,\n",
              " ('easi', 1.0): 7,\n",
              " ('guess', 1.0): 8,\n",
              " ('train', 1.0): 7,\n",
              " ('wd', 1.0): 1,\n",
              " ('shift', 1.0): 4,\n",
              " ('engin', 1.0): 1,\n",
              " ('etc', 1.0): 2,\n",
              " ('sunburn', 1.0): 1,\n",
              " ('peel', 1.0): 2,\n",
              " ('blog', 1.0): 27,\n",
              " ('huge', 1.0): 9,\n",
              " ('warm', 1.0): 4,\n",
              " ('☆', 1.0): 3,\n",
              " ('complet', 1.0): 10,\n",
              " ('triangl', 1.0): 2,\n",
              " ('northern', 1.0): 1,\n",
              " ('ireland', 1.0): 2,\n",
              " ('sight', 1.0): 1,\n",
              " ('smthng', 1.0): 2,\n",
              " ('fr', 1.0): 3,\n",
              " ('hug', 1.0): 11,\n",
              " ('xoxo', 1.0): 3,\n",
              " ('uu', 1.0): 1,\n",
              " ('jaann', 1.0): 1,\n",
              " ('topnewfollow', 1.0): 2,\n",
              " ('connect', 1.0): 13,\n",
              " ('wonder', 1.0): 26,\n",
              " ('made', 1.0): 38,\n",
              " ('fluffi', 1.0): 1,\n",
              " ('insid', 1.0): 7,\n",
              " ('pirouett', 1.0): 1,\n",
              " ('moos', 1.0): 1,\n",
              " ('trip', 1.0): 12,\n",
              " ('philli', 1.0): 1,\n",
              " ('decemb', 1.0): 2,\n",
              " (\"i'd\", 1.0): 13,\n",
              " ('dude', 1.0): 6,\n",
              " ('x41', 1.0): 1,\n",
              " ('question', 1.0): 15,\n",
              " ('flaw', 1.0): 1,\n",
              " ('pain', 1.0): 8,\n",
              " ('negat', 1.0): 1,\n",
              " ('strength', 1.0): 2,\n",
              " ('went', 1.0): 10,\n",
              " ('solo', 1.0): 4,\n",
              " ('move', 1.0): 9,\n",
              " ('fav', 1.0): 11,\n",
              " ('nirvana', 1.0): 1,\n",
              " ('smell', 1.0): 2,\n",
              " ('teen', 1.0): 3,\n",
              " ('spirit', 1.0): 1,\n",
              " ('rip', 1.0): 3,\n",
              " ('ami', 1.0): 4,\n",
              " ('winehous', 1.0): 1,\n",
              " ('coupl', 1.0): 5,\n",
              " ('tomhiddleston', 1.0): 1,\n",
              " ('elizabetholsen', 1.0): 1,\n",
              " ('yaytheylookgreat', 1.0): 1,\n",
              " ('goodnight', 1.0): 18,\n",
              " ('vid', 1.0): 8,\n",
              " ('wake', 1.0): 10,\n",
              " ('gonna', 1.0): 16,\n",
              " ('shoot', 1.0): 5,\n",
              " ('itti', 1.0): 2,\n",
              " ('bitti', 1.0): 2,\n",
              " ('teeni', 1.0): 2,\n",
              " ('bikini', 1.0): 3,\n",
              " ('much', 1.0): 73,\n",
              " ('4th', 1.0): 4,\n",
              " ('togeth', 1.0): 6,\n",
              " ('end', 1.0): 13,\n",
              " ('xfile', 1.0): 1,\n",
              " ('content', 1.0): 3,\n",
              " ('rain', 1.0): 18,\n",
              " ('fabul', 1.0): 4,\n",
              " ('fantast', 1.0): 8,\n",
              " ('♡', 1.0): 12,\n",
              " ('jb', 1.0): 1,\n",
              " ('forev', 1.0): 5,\n",
              " ('belieb', 1.0): 3,\n",
              " ('nighti', 1.0): 1,\n",
              " ('bug', 1.0): 2,\n",
              " ('bite', 1.0): 1,\n",
              " ('bracelet', 1.0): 2,\n",
              " ('idea', 1.0): 23,\n",
              " ('foundri', 1.0): 1,\n",
              " ('game', 1.0): 23,\n",
              " ('sens', 1.0): 6,\n",
              " ('pic', 1.0): 21,\n",
              " ('ef', 1.0): 1,\n",
              " ('phone', 1.0): 16,\n",
              " ('woot', 1.0): 2,\n",
              " ('derek', 1.0): 1,\n",
              " ('use', 1.0): 32,\n",
              " ('parkshar', 1.0): 1,\n",
              " ('gloucestershir', 1.0): 1,\n",
              " ('aaaahhh', 1.0): 1,\n",
              " ('man', 1.0): 16,\n",
              " ('traffic', 1.0): 2,\n",
              " ('stress', 1.0): 4,\n",
              " ('reliev', 1.0): 1,\n",
              " (\"how'r\", 1.0): 1,\n",
              " ('arbeloa', 1.0): 1,\n",
              " ('turn', 1.0): 13,\n",
              " ('17', 1.0): 2,\n",
              " ('omg', 1.0): 13,\n",
              " ('say', 1.0): 43,\n",
              " ('europ', 1.0): 1,\n",
              " ('rise', 1.0): 2,\n",
              " ('find', 1.0): 20,\n",
              " ('hard', 1.0): 9,\n",
              " ('believ', 1.0): 7,\n",
              " ('uncount', 1.0): 1,\n",
              " ('coz', 1.0): 2,\n",
              " ('unlimit', 1.0): 1,\n",
              " ('cours', 1.0): 11,\n",
              " ('teamposit', 1.0): 1,\n",
              " ('aldub', 1.0): 2,\n",
              " ('☕', 1.0): 3,\n",
              " ('rita', 1.0): 2,\n",
              " ('info', 1.0): 10,\n",
              " (\"we'd\", 1.0): 4,\n",
              " ('way', 1.0): 34,\n",
              " ('boy', 1.0): 13,\n",
              " ('x40', 1.0): 1,\n",
              " ('true', 1.0): 19,\n",
              " ('sethi', 1.0): 2,\n",
              " ('high', 1.0): 6,\n",
              " ('exe', 1.0): 1,\n",
              " ('skeem', 1.0): 1,\n",
              " ('saam', 1.0): 1,\n",
              " ('peopl', 1.0): 42,\n",
              " ('polit', 1.0): 2,\n",
              " ('izzat', 1.0): 1,\n",
              " ('wese', 1.0): 1,\n",
              " ('trust', 1.0): 7,\n",
              " ('khawateen', 1.0): 1,\n",
              " ('k', 1.0): 8,\n",
              " ('sath', 1.0): 2,\n",
              " ('mana', 1.0): 1,\n",
              " ('kar', 1.0): 1,\n",
              " ('deya', 1.0): 1,\n",
              " ('sort', 1.0): 7,\n",
              " ('smart', 1.0): 5,\n",
              " ('hair', 1.0): 7,\n",
              " ('tbh', 1.0): 5,\n",
              " ('jacob', 1.0): 2,\n",
              " ('g', 1.0): 7,\n",
              " ('upgrad', 1.0): 2,\n",
              " ('tee', 1.0): 2,\n",
              " ('famili', 1.0): 14,\n",
              " ('person', 1.0): 14,\n",
              " ('two', 1.0): 15,\n",
              " ('convers', 1.0): 6,\n",
              " ('onlin', 1.0): 4,\n",
              " ('mclaren', 1.0): 1,\n",
              " ('fridayfeel', 1.0): 5,\n",
              " ('tgif', 1.0): 8,\n",
              " ('squar', 1.0): 1,\n",
              " ('enix', 1.0): 1,\n",
              " ('bissmillah', 1.0): 1,\n",
              " ('ya', 1.0): 19,\n",
              " ('allah', 1.0): 3,\n",
              " (\"we'r\", 1.0): 25,\n",
              " ('socent', 1.0): 1,\n",
              " ('startup', 1.0): 2,\n",
              " ('drop', 1.0): 9,\n",
              " ('your', 1.0): 3,\n",
              " ('arnd', 1.0): 1,\n",
              " ('town', 1.0): 3,\n",
              " ('basic', 1.0): 4,\n",
              " ('piss', 1.0): 2,\n",
              " ('cup', 1.0): 4,\n",
              " ('also', 1.0): 28,\n",
              " ('terribl', 1.0): 2,\n",
              " ('complic', 1.0): 1,\n",
              " ('discuss', 1.0): 2,\n",
              " ('snapchat', 1.0): 31,\n",
              " ('lynettelow', 1.0): 1,\n",
              " ('kikmenow', 1.0): 2,\n",
              " ('snapm', 1.0): 1,\n",
              " ('hot', 1.0): 20,\n",
              " ('amazon', 1.0): 1,\n",
              " ('kikmeguy', 1.0): 2,\n",
              " ('defin', 1.0): 2,\n",
              " ('grow', 1.0): 6,\n",
              " ('sport', 1.0): 4,\n",
              " ('rt', 1.0): 9,\n",
              " ('rakyat', 1.0): 1,\n",
              " ('write', 1.0): 11,\n",
              " ('sinc', 1.0): 11,\n",
              " ('mention', 1.0): 18,\n",
              " ('fli', 1.0): 5,\n",
              " ('fish', 1.0): 3,\n",
              " ('promot', 1.0): 3,\n",
              " ('post', 1.0): 16,\n",
              " ('cyber', 1.0): 1,\n",
              " ('ourdaughtersourprid', 1.0): 3,\n",
              " ('mypapamyprid', 1.0): 2,\n",
              " ('papa', 1.0): 1,\n",
              " ('coach', 1.0): 2,\n",
              " ('posit', 1.0): 3,\n",
              " ('kha', 1.0): 1,\n",
              " ('atleast', 1.0): 2,\n",
              " ('x39', 1.0): 1,\n",
              " ('mango', 1.0): 1,\n",
              " (\"lassi'\", 1.0): 1,\n",
              " (\"monty'\", 1.0): 1,\n",
              " ('marvel', 1.0): 2,\n",
              " ('though', 1.0): 16,\n",
              " ('suspect', 1.0): 3,\n",
              " ('meant', 1.0): 2,\n",
              " ('24', 1.0): 3,\n",
              " ('hr', 1.0): 2,\n",
              " ('touch', 1.0): 7,\n",
              " ('kepler', 1.0): 3,\n",
              " ('452b', 1.0): 4,\n",
              " ('chalna', 1.0): 1,\n",
              " ('hai', 1.0): 7,\n",
              " ('thankyou', 1.0): 12,\n",
              " ('hazel', 1.0): 1,\n",
              " ('food', 1.0): 6,\n",
              " ('brooklyn', 1.0): 1,\n",
              " ('pta', 1.0): 2,\n",
              " ('awak', 1.0): 8,\n",
              " ('okayi', 1.0): 2,\n",
              " ('awww', 1.0): 12,\n",
              " ('ha', 1.0): 18,\n",
              " ('doc', 1.0): 1,\n",
              " ('splendid', 1.0): 1,\n",
              " ('spam', 1.0): 1,\n",
              " ('folder', 1.0): 1,\n",
              " ('amount', 1.0): 1,\n",
              " ('nigeria', 1.0): 1,\n",
              " ('claim', 1.0): 1,\n",
              " ('rted', 1.0): 1,\n",
              " ('leg', 1.0): 3,\n",
              " ('hurt', 1.0): 4,\n",
              " ('bad', 1.0): 14,\n",
              " ('mine', 1.0): 11,\n",
              " ('saturday', 1.0): 5,\n",
              " ('thaaank', 1.0): 1,\n",
              " ('puhon', 1.0): 1,\n",
              " ('happinesss', 1.0): 1,\n",
              " ('tnc', 1.0): 1,\n",
              " ('prior', 1.0): 1,\n",
              " ('notif', 1.0): 2,\n",
              " ('fat', 1.0): 1,\n",
              " ('co', 1.0): 1,\n",
              " ('probabl', 1.0): 7,\n",
              " ('ate', 1.0): 4,\n",
              " ('yuna', 1.0): 2,\n",
              " ('tamesid', 1.0): 1,\n",
              " ('´', 1.0): 3,\n",
              " ('googl', 1.0): 5,\n",
              " ('account', 1.0): 17,\n",
              " ('scouser', 1.0): 1,\n",
              " ('everyth', 1.0): 10,\n",
              " ('zoe', 1.0): 1,\n",
              " ('mate', 1.0): 5,\n",
              " ('liter', 1.0): 5,\n",
              " (\"they'r\", 1.0): 10,\n",
              " ('samee', 1.0): 1,\n",
              " ('edgar', 1.0): 1,\n",
              " ('updat', 1.0): 12,\n",
              " ('log', 1.0): 3,\n",
              " ('bring', 1.0): 12,\n",
              " ('abe', 1.0): 1,\n",
              " ('meet', 1.0): 26,\n",
              " ('x38', 1.0): 1,\n",
              " ('sigh', 1.0): 3,\n",
              " ('dreamili', 1.0): 1,\n",
              " ('pout', 1.0): 1,\n",
              " ('eye', 1.0): 12,\n",
              " ('quacketyquack', 1.0): 6,\n",
              " ('funni', 1.0): 15,\n",
              " ('happen', 1.0): 13,\n",
              " ('phil', 1.0): 1,\n",
              " ('em', 1.0): 2,\n",
              " ('del', 1.0): 1,\n",
              " ('rodder', 1.0): 1,\n",
              " ('els', 1.0): 8,\n",
              " ('play', 1.0): 37,\n",
              " ('newest', 1.0): 1,\n",
              " ('gamejam', 1.0): 1,\n",
              " ('irish', 1.0): 2,\n",
              " ('literatur', 1.0): 2,\n",
              " ('inaccess', 1.0): 2,\n",
              " (\"kareena'\", 1.0): 2,\n",
              " ('fan', 1.0): 21,\n",
              " ('brain', 1.0): 10,\n",
              " ('dot', 1.0): 8,\n",
              " ('braindot', 1.0): 8,\n",
              " ('fair', 1.0): 4,\n",
              " ('rush', 1.0): 1,\n",
              " ('either', 1.0): 10,\n",
              " ('brandi', 1.0): 1,\n",
              " ('18', 1.0): 5,\n",
              " ('carniv', 1.0): 1,\n",
              " ('men', 1.0): 8,\n",
              " ('put', 1.0): 11,\n",
              " ('mask', 1.0): 2,\n",
              " ('xavier', 1.0): 1,\n",
              " ('forneret', 1.0): 1,\n",
              " ('jennif', 1.0): 1,\n",
              " ('site', 1.0): 7,\n",
              " ('free', 1.0): 31,\n",
              " ('50.000', 1.0): 3,\n",
              " ('8', 1.0): 10,\n",
              " ('ball', 1.0): 7,\n",
              " ('pool', 1.0): 5,\n",
              " ('coin', 1.0): 5,\n",
              " ('edit', 1.0): 6,\n",
              " ('trish', 1.0): 1,\n",
              " ('♥', 1.0): 13,\n",
              " ('grate', 1.0): 5,\n",
              " ('three', 1.0): 8,\n",
              " ('comment', 1.0): 7,\n",
              " ('wakeup', 1.0): 1,\n",
              " ('besid', 1.0): 2,\n",
              " ('dirti', 1.0): 2,\n",
              " ('sex', 1.0): 4,\n",
              " ('lmaooo', 1.0): 1,\n",
              " ('😤', 1.0): 2,\n",
              " ('loui', 1.0): 4,\n",
              " (\"he'\", 1.0): 10,\n",
              " ('throw', 1.0): 3,\n",
              " ('caus', 1.0): 11,\n",
              " ('inspir', 1.0): 6,\n",
              " ('ff', 1.0): 40,\n",
              " ('twoof', 1.0): 3,\n",
              " ('gr8', 1.0): 1,\n",
              " ('wkend', 1.0): 3,\n",
              " ('kind', 1.0): 22,\n",
              " ('exhaust', 1.0): 2,\n",
              " ('word', 1.0): 17,\n",
              " ('cheltenham', 1.0): 1,\n",
              " ('area', 1.0): 4,\n",
              " ('kale', 1.0): 1,\n",
              " ('crisp', 1.0): 1,\n",
              " ('ruin', 1.0): 5,\n",
              " ('x37', 1.0): 1,\n",
              " ('open', 1.0): 12,\n",
              " ('worldwid', 1.0): 2,\n",
              " ('outta', 1.0): 1,\n",
              " ('sfvbeta', 1.0): 1,\n",
              " ('vantast', 1.0): 1,\n",
              " ('xcylin', 1.0): 1,\n",
              " ('bundl', 1.0): 1,\n",
              " ('show', 1.0): 20,\n",
              " ('internet', 1.0): 2,\n",
              " ('price', 1.0): 3,\n",
              " ('realisticli', 1.0): 1,\n",
              " ('pay', 1.0): 8,\n",
              " ('net', 1.0): 1,\n",
              " ('educ', 1.0): 1,\n",
              " ('power', 1.0): 6,\n",
              " ('weapon', 1.0): 1,\n",
              " ('nelson', 1.0): 1,\n",
              " ('mandela', 1.0): 1,\n",
              " ('recent', 1.0): 8,\n",
              " ('j', 1.0): 2,\n",
              " ('chenab', 1.0): 1,\n",
              " ('flow', 1.0): 5,\n",
              " ('pakistan', 1.0): 1,\n",
              " ('incredibleindia', 1.0): 1,\n",
              " ('teenchoic', 1.0): 7,\n",
              " ('choiceinternationalartist', 1.0): 7,\n",
              " ('superjunior', 1.0): 7,\n",
              " ('caught', 1.0): 4,\n",
              " ('first', 1.0): 41,\n",
              " ('salmon', 1.0): 1,\n",
              " ('super-blend', 1.0): 1,\n",
              " ('project', 1.0): 6,\n",
              " ('youth@bipolaruk.org.uk', 1.0): 1,\n",
              " ('awesom', 1.0): 35,\n",
              " ('stream', 1.0): 12,\n",
              " ('alma', 1.0): 1,\n",
              " ('mater', 1.0): 1,\n",
              " ('highschoolday', 1.0): 1,\n",
              " ('clientvisit', 1.0): 1,\n",
              " ('faith', 1.0): 3,\n",
              " ('christian', 1.0): 1,\n",
              " ('school', 1.0): 9,\n",
              " ('lizaminnelli', 1.0): 1,\n",
              " ('upcom', 1.0): 2,\n",
              " ('uk', 1.0): 4,\n",
              " ('😄', 1.0): 3,\n",
              " ('singl', 1.0): 4,\n",
              " ('hill', 1.0): 4,\n",
              " ('everi', 1.0): 23,\n",
              " ('beat', 1.0): 7,\n",
              " ('wrong', 1.0): 9,\n",
              " ('readi', 1.0): 22,\n",
              " ('natur', 1.0): 1,\n",
              " ('pefumeri', 1.0): 1,\n",
              " ('workshop', 1.0): 2,\n",
              " ('neal', 1.0): 1,\n",
              " ('yard', 1.0): 1,\n",
              " ('covent', 1.0): 1,\n",
              " ('tomorrow', 1.0): 31,\n",
              " ('fback', 1.0): 26,\n",
              " ('indo', 1.0): 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GMTiRlR5ue5"
      },
      "source": [
        "### Procesamiento del tweet\n",
        "\n",
        "La función dada `process_tweet ()` tokeniza el tweet en palabras individuales, elimina las palabras vacías y aplica la derivación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_4zf0a2z5ue5",
        "outputId": "b9d29c2b-0ea8-47e3-888e-02744f2ce194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "process_tweet(train_x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKXLOd8Q5ue5"
      },
      "source": [
        "##  Extrayendo las características\n",
        "\n",
        "* Dada una lista de tweets, extraiga las características y guárdelas en una matriz. Extraerás dos características.\n",
        "     * La primera característica es la cantidad de palabras positivas en un tweet.\n",
        "     * La segunda característica es la cantidad de palabras negativas en un tweet.\n",
        "* Luego entrene su clasificador de regresión logística en estas características.\n",
        "* Pruebe el clasificador en un conjunto de validación.\n",
        "\n",
        "### Implementación de la función de extract_features.\n",
        "* Esta función admite un solo tweet.\n",
        "* Procesaremos el tweet usando la función `process_tweet()` importada y la guardaremos en la lista de palabras del tweet.\n",
        "* Recorreremos cada palabra en la lista de palabras procesadas\n",
        "     * Para cada palabra, consultaremos el diccionario `freqs` para el recuento cuando esa palabra tiene una etiqueta positiva '1'. (con clave (palabra, 1.0)\n",
        "     * Hacemos lo mismo con el recuento para cuando la palabra esté asociada con la etiqueta negativa '0'. (con la clave (palabra, 0.0).)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freqs.get(('followfriday',1.0), 1)\n"
      ],
      "metadata": {
        "id": "2Cn4Q8FYGvrt",
        "outputId": "94c17efa-3a4f-44b7-d122-918edbfdbc35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Qu_gNJyl5ue5"
      },
      "outputs": [],
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    # procesar el tweet (tokenizar, stems, remover stopwords, regex)\n",
        "    word_l = process_tweet(tweet)\n",
        "\n",
        "    #Crear el vector x (1x3)\n",
        "    x = np.zeros((1,3))\n",
        "    #bias en 1\n",
        "    x[0,0]=1\n",
        "\n",
        "    for word in word_l:\n",
        "      #El conteo para los tokens que vienen de un tweet positivo\n",
        "      x[0,1] += freqs.get((word,1.0), 1)\n",
        "\n",
        "      #El conteo de los tokens que vienen de un tweet negativo\n",
        "      x[0,2] += freqs.get((word,0.0),0)\n",
        "\n",
        "    assert(x.shape==(1,3))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ILxo32_z5ue5",
        "outputId": "3c89775c-ebc5-4dab-a2c6-202d92b1af43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00e+00 3.02e+03 6.10e+01]]\n"
          ]
        }
      ],
      "source": [
        "# checar la función\n",
        "tmp1 = extract_features(train_x[0], freqs)\n",
        "print(tmp1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CLg3M7K5ue5"
      },
      "source": [
        "# Implementación de la Regresión Logística\n",
        "\n",
        "\n",
        "### Función sigmoide\n",
        "Aprenderá a utilizar la regresión logística para la clasificación de texto.\n",
        "* La función sigmoidea se define como:\n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
        "\n",
        "Asigna la entrada 'z' a un valor que varía entre 0 y 1, por lo que puede tratarse como una probabilidad.\n",
        "\n",
        "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='https://github.com/gdesirena/Procesamiento_Natural_del_Lenguaje_2024/blob/main/Modulo%20II/Figures/sigmoid_plot.jpg?raw=1' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:200px;\" /> </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "QOH1JIVc5ue6"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MAzeiHzN5ue6",
        "outputId": "3a9e7b53-a0cf-4590-e28a-d7101b1a6181",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# probar la función\n",
        "sigmoid(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(4.58)"
      ],
      "metadata": {
        "id": "wQRCOt4FHbGg",
        "outputId": "43a30305-3cf0-403a-a1c8-f0bf09d0e946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9898491991140074"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(-4.58)"
      ],
      "metadata": {
        "id": "9rHtG61yHbOB",
        "outputId": "930cb3ad-54d2-4a86-ab04-6d770be525c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01015080088599272"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6GQFszv5ue6"
      },
      "source": [
        "### Logistic regression: regression y función sigmoide\n",
        "\n",
        "La regresión logística toma una regresión lineal regular y aplica un sigmoide a la salida de la regresión lineal.\n",
        "\n",
        "Regresion:\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Tenga en cuenta que los valores $ \\theta $ son \"pesos\". Si realizó la especialización en aprendizaje profundo, nos referimos a los pesos con el vector `w`. En este curso, usamos una variable diferente $ \\theta $ para referirnos a los pesos.\n",
        "\n",
        "Regresión logística\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Nos referiremos a 'z' como los 'logits'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB2Wt_u65ue6"
      },
      "source": [
        "### Función de costo y gradiente\n",
        "\n",
        "La función de costo utilizada para la regresión logística es el promedio de la pérdida de registro en todos los ejemplos de entrenamiento:\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
        "* $m$ es la cantidad de ejemplos de entrenamiento\n",
        "* $y^{(i)}$ es la etiqueta real del i-ésimo dato de entrenamiento.\n",
        "* $h(z(\\theta)^{(i)})$ es la predicción del modelo para el i-ésimo ejemplo de entrenamiento.\n",
        "\n",
        "La función de pérdida para un solo ejemplo de entrenamiento es\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* Todos los valores de $ h $ están entre 0 y 1, por lo que los registros serán negativos. Esa es la razón del factor -1 aplicado a la suma de los dos términos de pérdida.\n",
        "* Tenga en cuenta que cuando el modelo predice 1 ($ h (z (\\theta)) = 1 $) y la etiqueta $ y $ también es 1, la pérdida para ese ejemplo de entrenamiento es 0.\n",
        "* De manera similar, cuando el modelo predice 0 ($ h (z (\\theta)) = 0 $) y la etiqueta real también es 0, la pérdida para ese ejemplo de entrenamiento es 0.\n",
        "* Sin embargo, cuando la predicción del modelo es cercana a 1 ($ h (z (\\theta)) = 0.9999 $) y la etiqueta es 0, el segundo término de la pérdida logarítmica se convierte en un gran número negativo, que luego se multiplica por el factor general de -1 para convertirlo en un valor de pérdida positivo. $ -1 \\times (1 - 0) \\times log (1 - 0.9999) \\approx 9.2 $ Cuanto más se acerque la predicción del modelo a 1, mayor será la pérdida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTXYL2zY5ue6"
      },
      "source": [
        "* Del mismo modo, si el modelo predice cerca de 0 ($ h (z) = 0.0001 $) pero la etiqueta real es 1, el primer término en la función de pérdida se convierte en un número grande: $ -1 \\times log (0.0001) \\approx 9.2 $. Cuanto más cercana sea la predicción a cero, mayor será la pérdida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "EJantc7j5ue6",
        "outputId": "85639db8-fc97-4c81-bb92-f194946276e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976182"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "#verificar que cuando el modelo predice cerca de 0 pero la etiqueta real es 1, la pérdida es un valor positivo grande\n",
        "-1 * np.log(0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqOXSd3w5ue7"
      },
      "source": [
        "#### Actualizar los pesos\n",
        "\n",
        "Para actualizar su vector de peso $ \\theta $, aplicará el descenso de gradiente para mejorar iterativamente las predicciones de su modelo.\n",
        "El gradiente de la función de costo $ J $ con respecto a uno de los pesos $ \\theta_j $ es:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j \\tag{5}$$\n",
        "* 'i' es el índice de todos los ejemplos de formación \"m\".\n",
        "* 'j' es el índice del peso $ \\theta_j $, entonces $ x_j $ es la característica asociada con el peso $ \\theta_j $\n",
        "\n",
        "* Para actualizar el peso $ \\theta_j $, lo ajustamos restando una fracción del gradiente determinado por $ \\alpha $:\n",
        "$$ \\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j} J (\\theta) $$\n",
        "* La tasa de aprendizaje $ \\alpha $ es un valor que elegimos para controlar qué tan grande será una sola actualización.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSmgL_tL5ue7"
      },
      "source": [
        "## Implementación de la función Gradiente Descendente\n",
        "* El número de iteraciones `num_iters` es el número de veces que utilizará todo el conjunto de entrenamiento.\n",
        "* Para cada iteración, calculará la función de costo usando todos los ejemplos de entrenamiento (hay ejemplos de entrenamiento `m`), y para todas las funciones.\n",
        "* En lugar de actualizar un solo peso $ \\theta_i $ a la vez, podemos actualizar todos los pesos en el vector de columna:  \n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\\n",
        "\\theta_2\n",
        "\\\\\n",
        "\\vdots\n",
        "\\\\\n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "* $ \\mathbf {\\theta} $ tiene dimensiones (n + 1, 1), donde 'n' es el número de características, y hay un elemento más para el término de sesgo $ \\theta_0 $ (tenga en cuenta que el valor de característica correspondiente $ \\mathbf {x_0} $ es 1).\n",
        "* Los 'logits', 'z', se calculan multiplicando la matriz de características 'x' con el vector de peso 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
        "    * $\\mathbf{x}$ has dimensions (m, n+1)\n",
        "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
        "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
        "* La predicción 'h' se calcula aplicando el sigmoide a cada elemento en 'z': $ h (z) = sigmoid (z) $, y tiene dimensiones (m, 1).\n",
        "* La función de costo $ J $ se calcula tomando el producto escalar de los vectores 'y' y 'log (h)'. Dado que tanto 'y' como 'h' son vectores de columna (m, 1), transponga el vector a la izquierda, de modo que la multiplicación de matrices de un vector de fila con un vector de columna realice el producto escalar.\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
        "* La actualización de theta también está vectorizada. Debido a que las dimensiones de $ \\mathbf {x} $ son (m, n + 1), y tanto $ \\mathbf {h} $ como $ \\mathbf {y} $ son (m, 1), necesitamos transponer $ \\mathbf {x} $ y colóquelo a la izquierda para realizar la multiplicación de matrices, que luego da la respuesta (n + 1, 1) que necesitamos:\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Xh9MRYBM5ue7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "      z = np.dot(x,theta)\n",
        "      h = sigmoid(z)\n",
        "\n",
        "      J = -1/m * (np.dot(y.transpose(), np.log(h)) + np.dot((1-y).transpose(), np.log(1-h)))\n",
        "\n",
        "      theta = theta - (alpha/m)*np.dot(x.transpose(), (h-y))\n",
        "\n",
        "      J = float(J)\n",
        "    return J, theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQevcJBo5ue7"
      },
      "source": [
        "# Actividad 3: Modelo de Regresión Logística para Análisis de Sentimientos de tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coBT7VFB5ue7"
      },
      "source": [
        "### 1.- Entrenar el modelo\n",
        "\n",
        "**instrucciones: Para entrenar el modelo:**\n",
        "\n",
        "* Apile las características de todos los datos de entrenamiento en una matriz `X`.\n",
        "* Llame la función `gradientDescent`, que se implementó anteriormente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "h1_zm4bj5ue7"
      },
      "outputs": [],
      "source": [
        "# recolectar todos los features apartir de la función extract_features\n",
        "X = np.zeros((len(train_x),3))\n",
        "for i in range(len(train_x)):\n",
        "  X[i,:] = extract_features(train_x[i], freqs)\n",
        "\n",
        "# Obtener las etiquetas reales (el valor de y) train_y\n",
        "Y= train_y\n",
        "\n",
        "# Aplicar el gradiente descendente\n",
        "theta_0 = np.zeros((3,1)) # vector de 3x1 (inicializar aleatoriamente, o con zeros)\n",
        "J, theta = gradientDescent(X,Y,theta_0, 1e-9, 1500)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theta"
      ],
      "metadata": {
        "id": "R2RFQgS0Nhyf",
        "outputId": "ab57f25e-7b28-471c-9f17-f5c0d0035fd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.25222017e-08],\n",
              "       [ 5.23753412e-04],\n",
              "       [-5.55251200e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlVysRLb5ue8"
      },
      "source": [
        "### 2.- Probando la regresión logística\n",
        "\n",
        "**Instrucciones para Predecir si un tweet es positivo o negativo**\n",
        "\n",
        "* Dado un tweet, procéselo y luego extraiga las características.\n",
        "* Aplicar los pesos aprendidos del modelo para obtener los logits.\n",
        "* Aplicar la función sigmoide a los logits para obtener la predicción (un valor entre 0 y 1).\n",
        "\n",
        "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "98B0zMFU5ue8"
      },
      "outputs": [],
      "source": [
        "# UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "\n",
        "    #extraer los features con la función extract featurs X\n",
        "    x = extract_features(tweet, freqs)\n",
        "\n",
        "    #predecir utilizando la ecuacion de arriba ypred = sigmoid(np.dot(x, theta))\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "    if y_pred >0.5:\n",
        "      y_hat = 1\n",
        "    else:\n",
        "      y_hat = 0\n",
        "\n",
        "    return y_pred, y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "X9VcbIHO5ue8",
        "outputId": "2493cb85-4765-46f0-df51-d3c3d76f46cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy ---> (array([[0.51857391]]), 1)\n",
            "I am bad ---> (array([[0.49433751]]), 0)\n",
            "This movie is amazing ---> (array([[0.50356881]]), 1)\n",
            "great movie ---> (array([[0.5153249]]), 1)\n"
          ]
        }
      ],
      "source": [
        "tweets_test = ['I am happy', 'I am bad', 'This movie is amazing', 'great movie']\n",
        "for tw in tweets_test:\n",
        "  print(f'{tw} ---> {predict_tweet(tw, freqs,theta)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80BfnIgl5ue8"
      },
      "source": [
        "### 3.- Verificando el rendimiento del modelo\n",
        "\n",
        "Después de entrenar su modelo con el conjunto de entrenamiento anterior, verifique cómo podría funcionar su modelo en datos reales no vistos probándolo con el conjunto de prueba.\n",
        "\n",
        "**Instrucciones: Implementar `test_logistic_regression`**\n",
        "\n",
        "* Dados los datos de prueba y los pesos de su modelo entrenado, calcule la precisión de su modelo de regresión logística.\n",
        "* Utilice su función `predict_tweet ()` para hacer predicciones en cada tweet en el conjunto de prueba.\n",
        "* Si la predicción es> 0,5, establezca la clasificación del modelo `y_hat` en 1; de lo contrario, establezca la clasificación del modelo` y_hat` en 0.\n",
        "* Una predicción es precisa cuando `y_hat` es igual a` test_y`. Para calcular la precisón sume todas las instancias en las que ($y_hat==test_y$) sean iguales y divida por `m`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byNb5piH5ue8"
      },
      "outputs": [],
      "source": [
        "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)None\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPiF3csd5ue8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgsnkbyG5ue8"
      },
      "source": [
        "### 4.- Predice tu propio tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HrMr7m15ue9"
      },
      "outputs": [],
      "source": [
        "# Feel free to change the tweet below\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_UABv9ymPopl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpyOwrJCPpRj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "coursera": {
      "schema_names": [
        "NLPC1-1"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}